import pandas as pd
import json
import numpy as np
import os
import subprocess
import sys

print("=" * 80)
print("ğŸš€ ä¸€é”®å¼æ•°æ®å¤„ç† + HDFSä¸Šä¼  + Hiveå¯¼å…¥")
print("=" * 80)

# ==========================================
# 1. è¯»å–åŸå§‹æ•°æ®
# ==========================================
print("\n>>> [æ­¥éª¤ 1] è¯»å–åŸå§‹æ•°æ®...")

if not os.path.exists('tmdb_5000_movies.csv'):
    print("âŒ é”™è¯¯ï¼šæ²¡æ‰¾åˆ° tmdb_5000_movies.csvï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
    sys.exit(1)

if not os.path.exists('tmdb_5000_credits.csv'):
    print("âŒ é”™è¯¯ï¼šæ²¡æ‰¾åˆ° tmdb_5000_credits.csvï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
    sys.exit(1)

movies = pd.read_csv('tmdb_5000_movies.csv')
credits = pd.read_csv('tmdb_5000_credits.csv')

print(f"   âœ… è¯»å–ç”µå½±æ•°æ®: {len(movies)} éƒ¨")
print(f"   âœ… è¯»å–æ¼”èŒå‘˜æ•°æ®: {len(credits)} æ¡")

# ==========================================
# 2. åˆå¹¶æ•°æ®ï¼ˆé¿å…åˆ—åå†²çªï¼‰
# ==========================================
print("\n>>> [æ­¥éª¤ 2] åˆå¹¶æ•°æ®...")

credits_renamed = credits[['movie_id', 'cast', 'crew']]
movies = movies.merge(credits_renamed, left_on='id', right_on='movie_id', how='left')

print(f"   âœ… åˆå¹¶åæ•°æ®é‡: {len(movies)} éƒ¨")

# ==========================================
# 3. æ¸…æ´— JSON æ•°æ®
# ==========================================
print("\n>>> [æ­¥éª¤ 3] è§£æ JSON æ ¼å¼çš„å¤æ‚åˆ—...")

def get_names(obj):
    """æå– JSON æ•°ç»„ä¸­çš„ name å­—æ®µï¼Œç”¨ç«–çº¿åˆ†éš”"""
    try:
        if pd.isna(obj):
            return ""
        L = json.loads(obj)
        return "|".join([i['name'] for i in L[:5]])
    except:
        return ""

def get_director(obj):
    """ä» crew ä¸­æå–å¯¼æ¼”åå­—"""
    try:
        if pd.isna(obj):
            return ""
        L = json.loads(obj)
        for i in L:
            if i.get('job') == 'Director':
                return i.get('name', '')
        return ""
    except:
        return ""

print("   æ­£åœ¨è§£æ genres...")
movies['genres_str'] = movies['genres'].apply(get_names)

print("   æ­£åœ¨è§£æ keywords...")
movies['keywords_str'] = movies['keywords'].apply(get_names)

print("   æ­£åœ¨è§£æ cast...")
movies['cast_str'] = movies['cast'].apply(get_names)

print("   æ­£åœ¨è§£æ director...")
movies['director'] = movies['crew'].apply(get_director)

print("   âœ… JSON è§£æå®Œæˆ")

# ==========================================
# 4. æ•°æ®æ¸…æ´—
# ==========================================
print("\n>>> [æ­¥éª¤ 4] æ•°æ®æ¸…æ´—...")

# å¤„ç†æ—¥æœŸ
print("   å¤„ç†æ—¥æœŸæ ¼å¼...")
movies['release_date'] = pd.to_datetime(movies['release_date'], errors='coerce').dt.date

# å¡«è¡¥ç©ºå€¼
print("   å¡«è¡¥ç¼ºå¤±å€¼...")
mean_revenue = movies[movies['revenue'] > 0]['revenue'].mean()
mean_budget = movies[movies['budget'] > 0]['budget'].mean()

movies['revenue'] = movies['revenue'].replace(0, mean_revenue)
movies['budget'] = movies['budget'].replace(0, mean_budget)

movies['popularity'] = movies['popularity'].fillna(0)
movies['vote_average'] = movies['vote_average'].fillna(0)
movies['vote_count'] = movies['vote_count'].fillna(0)
movies['runtime'] = movies['runtime'].fillna(0)

print(f"   âœ… å‡å€¼å¡«è¡¥: revenue={mean_revenue:,.0f}, budget={mean_budget:,.0f}")

# æ¸…ç†æ–‡æœ¬
print("   æ¸…ç†æ–‡æœ¬ç‰¹æ®Šå­—ç¬¦...")
def clean_text(text):
    if isinstance(text, str):
        return text.replace('\t', ' ').replace('\n', ' ').replace('\r', ' ').strip()
    return text

movies['title'] = movies['title'].apply(clean_text)
movies['genres_str'] = movies['genres_str'].apply(clean_text)
movies['keywords_str'] = movies['keywords_str'].apply(clean_text)
movies['director'] = movies['director'].apply(clean_text)

# å¤„ç†ç©ºå­—ç¬¦ä¸²
movies['genres_str'] = movies['genres_str'].replace('', '-')
movies['keywords_str'] = movies['keywords_str'].replace('', '-')
movies['director'] = movies['director'].replace('', 'Unknown')

print("   âœ… æ–‡æœ¬æ¸…ç†å®Œæˆ")

# ==========================================
# 5. ä¿å­˜æ¸…æ´—åçš„ç”µå½±æ•°æ®
# ==========================================
print("\n>>> [æ­¥éª¤ 5] ä¿å­˜æ¸…æ´—åçš„ç”µå½±æ•°æ®...")

clean_cols = [
    'id', 'title', 'budget', 'revenue', 'popularity', 
    'vote_average', 'vote_count', 'runtime', 
    'genres_str', 'keywords_str', 'director', 'release_date'
]

movies_clean = movies[clean_cols].copy()
movies_clean.columns = [
    'id', 'title', 'budget', 'revenue', 'popularity',
    'vote_average', 'vote_count', 'runtime',
    'genres', 'keywords', 'director', 'release_date'
]

output_file = 'clean_movies.txt'
movies_clean.to_csv(output_file, index=False, sep='\t', header=False)

print(f"   âœ… å·²ä¿å­˜: {output_file}")
print(f"   âœ… æ•°æ®é‡: {len(movies_clean)} éƒ¨ç”µå½±")

# ==========================================
# 6. ç”Ÿæˆè™šæ‹Ÿè¯„åˆ†æ•°æ®
# ==========================================
print("\n>>> [æ­¥éª¤ 6] ç”Ÿæˆè™šæ‹Ÿè¯„åˆ†æ•°æ®...")

n_users = 1000
n_top_movies = 2000

movies['popularity'] = pd.to_numeric(movies['popularity'], errors='coerce')
top_movies = movies.nlargest(n_top_movies, 'popularity')['id'].values

print(f"   é€‰æ‹©çƒ­åº¦å‰ {n_top_movies} éƒ¨ç”µå½±")
print(f"   ç”Ÿæˆ {n_users} ä¸ªè™šæ‹Ÿç”¨æˆ·çš„è¯„åˆ†...")

ratings_list = []

for user_id in range(1, n_users + 1):
    num_seen = np.random.randint(20, 50)
    movies_seen = np.random.choice(top_movies, num_seen, replace=False)
    
    for movie_id in movies_seen:
        rating = np.random.choice([3, 4, 5, 1, 2], p=[0.3, 0.4, 0.2, 0.05, 0.05])
        ratings_list.append([user_id, int(movie_id), float(rating)])
    
    if user_id % 200 == 0:
        print(f"   è¿›åº¦: {user_id}/{n_users} ç”¨æˆ·")

ratings_df = pd.DataFrame(ratings_list, columns=['userId', 'movieId', 'rating'])

ratings_file = 'fake_ratings.txt'
ratings_df.to_csv(ratings_file, index=False, sep=',', header=False)

print(f"   âœ… å·²ä¿å­˜: {ratings_file}")
print(f"   âœ… è¯„åˆ†æ•°é‡: {len(ratings_df):,} æ¡")

# ==========================================
# 7. ä¸Šä¼ åˆ° HDFS
# ==========================================
print("\n>>> [æ­¥éª¤ 7] ä¸Šä¼ æ–‡ä»¶åˆ° HDFS...")

hdfs_dir = "/bigdata_project/data"

# åˆ›å»º HDFS ç›®å½•
print(f"   åˆ›å»º HDFS ç›®å½•: {hdfs_dir}")
subprocess.run(['hdfs', 'dfs', '-mkdir', '-p', hdfs_dir], 
               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# åˆ é™¤æ—§æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
print("   åˆ é™¤æ—§æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰...")
subprocess.run(['hdfs', 'dfs', '-rm', '-f', f'{hdfs_dir}/clean_movies.txt'], 
               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
subprocess.run(['hdfs', 'dfs', '-rm', '-f', f'{hdfs_dir}/fake_ratings.txt'], 
               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# ä¸Šä¼ æ–°æ–‡ä»¶
print(f"   ä¸Šä¼  {output_file} åˆ° HDFS...")
result = subprocess.run(['hdfs', 'dfs', '-put', output_file, hdfs_dir], 
                       capture_output=True, text=True)
if result.returncode == 0:
    print(f"   âœ… {output_file} ä¸Šä¼ æˆåŠŸ")
else:
    print(f"   âŒ {output_file} ä¸Šä¼ å¤±è´¥: {result.stderr}")
    sys.exit(1)

print(f"   ä¸Šä¼  {ratings_file} åˆ° HDFS...")
result = subprocess.run(['hdfs', 'dfs', '-put', ratings_file, hdfs_dir], 
                       capture_output=True, text=True)
if result.returncode == 0:
    print(f"   âœ… {ratings_file} ä¸Šä¼ æˆåŠŸ")
else:
    print(f"   âŒ {ratings_file} ä¸Šä¼ å¤±è´¥: {result.stderr}")
    sys.exit(1)

# ==========================================
# 8. å¯¼å…¥åˆ° Hive
# ==========================================
print("\n>>> [æ­¥éª¤ 8] å¯¼å…¥æ•°æ®åˆ° Hive...")

# åˆ›å»º Hive SQL è„šæœ¬
hive_sql = """
-- åˆ›å»ºæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
CREATE DATABASE IF NOT EXISTS movie_db;

-- åˆ é™¤æ—§è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
DROP TABLE IF EXISTS movie_db.movies;
DROP TABLE IF EXISTS movie_db.ratings;

-- åˆ›å»ºç”µå½±è¡¨
CREATE TABLE movie_db.movies (
    id INT,
    title STRING,
    budget DOUBLE,
    revenue DOUBLE,
    popularity DOUBLE,
    vote_average DOUBLE,
    vote_count INT,
    runtime DOUBLE,
    genres STRING,
    keywords STRING,
    director STRING,
    release_date DATE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\\t'
STORED AS TEXTFILE;

-- åŠ è½½ç”µå½±æ•°æ®
LOAD DATA INPATH '/bigdata_project/data/clean_movies.txt' 
INTO TABLE movie_db.movies;

-- åˆ›å»ºè¯„åˆ†è¡¨
CREATE TABLE movie_db.ratings (
    userId INT,
    movieId INT,
    rating DOUBLE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

-- åŠ è½½è¯„åˆ†æ•°æ®
LOAD DATA INPATH '/bigdata_project/data/fake_ratings.txt' 
INTO TABLE movie_db.ratings;

-- æ˜¾ç¤ºè¡¨ä¿¡æ¯
SHOW TABLES IN movie_db;
"""

# ä¿å­˜ SQL è„šæœ¬
sql_file = 'load_to_hive.sql'
with open(sql_file, 'w') as f:
    f.write(hive_sql)

print(f"   âœ… å·²ç”Ÿæˆ Hive SQL è„šæœ¬: {sql_file}")

# æ‰§è¡Œ Hive SQL
print("   æ­£åœ¨æ‰§è¡Œ Hive SQL...")
print("   âš ï¸  æ³¨æ„ï¼šä¼šåˆ é™¤æ—§è¡¨å¹¶é‡æ–°åˆ›å»ºï¼")

result = subprocess.run(['hive', '-f', sql_file], 
                       capture_output=True, text=True)

if result.returncode == 0:
    print("   âœ… Hive è¡¨åˆ›å»ºå’Œæ•°æ®åŠ è½½æˆåŠŸ")
    # æ˜¾ç¤ºéƒ¨åˆ†è¾“å‡º
    if "OK" in result.stdout:
        print("   âœ… Hive å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
else:
    print(f"   âŒ Hive æ‰§è¡Œå¤±è´¥")
    print(f"   é”™è¯¯ä¿¡æ¯: {result.stderr}")
    sys.exit(1)

# ==========================================
# 9. éªŒè¯æ•°æ®
# ==========================================
print("\n>>> [æ­¥éª¤ 9] éªŒè¯ Hive è¡¨æ•°æ®...")

verify_sql = """
SELECT COUNT(*) as movie_count FROM movie_db.movies;
SELECT COUNT(*) as rating_count FROM movie_db.ratings;
"""

verify_file = 'verify_hive.sql'
with open(verify_file, 'w') as f:
    f.write(verify_sql)

result = subprocess.run(['hive', '-f', verify_file], 
                       capture_output=True, text=True)

if result.returncode == 0:
    print("   âœ… æ•°æ®éªŒè¯æˆåŠŸ")
    print(f"   è¾“å‡º:\n{result.stdout}")
else:
    print(f"   âš ï¸  éªŒè¯å¤±è´¥ï¼Œä½†æ•°æ®å¯èƒ½å·²ç»åŠ è½½")

# ==========================================
# 10. æ•°æ®ç»Ÿè®¡
# ==========================================
print("\n" + "=" * 80)
print("ğŸ“Š æ•°æ®ç»Ÿè®¡")
print("=" * 80)

print(f"\nç”µå½±æ•°æ®:")
print(f"  â€¢ æ€»æ•°: {len(movies_clean)} éƒ¨")
print(f"  â€¢ é¢„ç®—èŒƒå›´: ${movies_clean['budget'].min():,.0f} - ${movies_clean['budget'].max():,.0f}")
print(f"  â€¢ ç¥¨æˆ¿èŒƒå›´: ${movies_clean['revenue'].min():,.0f} - ${movies_clean['revenue'].max():,.0f}")

print(f"\nè¯„åˆ†æ•°æ®:")
print(f"  â€¢ ç”¨æˆ·æ•°: {ratings_df['userId'].nunique()}")
print(f"  â€¢ ç”µå½±æ•°: {ratings_df['movieId'].nunique()}")
print(f"  â€¢ è¯„åˆ†æ•°: {len(ratings_df):,} æ¡")

print(f"\nHDFS è·¯å¾„:")
print(f"  â€¢ ç”µå½±æ•°æ®: {hdfs_dir}/clean_movies.txt")
print(f"  â€¢ è¯„åˆ†æ•°æ®: {hdfs_dir}/fake_ratings.txt")

print(f"\nHive è¡¨:")
print(f"  â€¢ æ•°æ®åº“: movie_db")
print(f"  â€¢ ç”µå½±è¡¨: movie_db.movies")
print(f"  â€¢ è¯„åˆ†è¡¨: movie_db.ratings")

print("\n" + "=" * 80)
print("âœ… å…¨éƒ¨å®Œæˆï¼æ•°æ®å·²æˆåŠŸå¯¼å…¥ Hive")
print("=" * 80)

print("\nä¸‹ä¸€æ­¥:")
print("  1. è¿è¡Œ: spark-submit --master yarn etl2.py")
print("  2. è¿è¡Œ: spark-submit --master yarn train2.py")
print("  3. è¿è¡Œ: python app2.py")

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
print("\n>>> æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
try:
    os.remove(sql_file)
    os.remove(verify_file)
    print("   âœ… ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
except:
    pass

